{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "import ast\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "#Function to pre process the given tag\n",
    "def data_preprocess(txt):\n",
    "    try:\n",
    "        result_tag=[]\n",
    "        txt=ast.literal_eval(str(txt))\n",
    "        txt=' '.join(txt)        \n",
    "        for tkn in gensim.utils.simple_preprocess(txt):\n",
    "            if tkn not in gensim.parsing.preprocessing.STOPWORDS and len(tkn) > 3:\n",
    "                result_tag.append(lemmatization_and_stemming(tkn))\n",
    "        return result_tag \n",
    "    except ValueError:\n",
    "        return 'NA'\n",
    "    \n",
    "#Applying lemmatization and stemming on the given tag    \n",
    "def lemmatization_and_stemming(txt):\n",
    "    stemmer_function = SnowballStemmer(language='english')\n",
    "    return stemmer_function.stem(WordNetLemmatizer().lemmatize(txt, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sk714\\AppData\\Local\\Temp\\ipykernel_17496\\4017450386.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_tags['index'] = data_tags.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.115*\"action\" + 0.089*\"platform\" + 0.058*\"adventur\" + 0.045*\"singleplay\" + 0.043*\"pixel\" + 0.043*\"graphic\" + 0.033*\"casual\" + 0.029*\"retro\" + 0.028*\"arcad\" + 0.025*\"shooter\"\n",
      "Topic: 1 \n",
      "Words: 0.091*\"horror\" + 0.078*\"adventur\" + 0.045*\"action\" + 0.043*\"person\" + 0.040*\"atmospher\" + 0.036*\"singleplay\" + 0.035*\"dark\" + 0.034*\"psycholog\" + 0.032*\"surviv\" + 0.027*\"violent\"\n",
      "Topic: 2 \n",
      "Words: 0.053*\"adventur\" + 0.048*\"rich\" + 0.044*\"stori\" + 0.036*\"anim\" + 0.033*\"protagonist\" + 0.033*\"femal\" + 0.031*\"singleplay\" + 0.030*\"choic\" + 0.030*\"matter\" + 0.030*\"novel\"\n",
      "Topic: 3 \n",
      "Words: 0.069*\"casual\" + 0.058*\"singleplay\" + 0.052*\"puzzl\" + 0.042*\"relax\" + 0.042*\"friend\" + 0.040*\"famili\" + 0.030*\"color\" + 0.026*\"atmospher\" + 0.022*\"game\" + 0.021*\"cute\"\n",
      "Topic: 4 \n",
      "Words: 0.193*\"simul\" + 0.142*\"casual\" + 0.112*\"strategi\" + 0.067*\"manag\" + 0.040*\"build\" + 0.031*\"action\" + 0.023*\"illustr\" + 0.023*\"design\" + 0.022*\"time\" + 0.020*\"sandbox\"\n",
      "Topic: 5 \n",
      "Words: 0.081*\"action\" + 0.057*\"strategi\" + 0.055*\"base\" + 0.049*\"adventur\" + 0.042*\"turn\" + 0.037*\"play\" + 0.037*\"free\" + 0.031*\"multiplay\" + 0.030*\"earli\" + 0.030*\"access\"\n",
      "Topic: 6 \n",
      "Words: 0.077*\"multiplay\" + 0.064*\"local\" + 0.051*\"sport\" + 0.046*\"race\" + 0.037*\"action\" + 0.024*\"softwar\" + 0.024*\"parti\" + 0.023*\"tabletop\" + 0.023*\"base\" + 0.021*\"strategi\"\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json('../dataset/games.jl',lines=True, encoding='utf-8')\n",
    "data_tags = data[['tags']]\n",
    "data_tags['index'] = data_tags.index\n",
    "\n",
    "#pre processing the game tags\n",
    "processed_tags = data_tags['tags'].map(data_preprocess)\n",
    "processed_tags=processed_tags[processed_tags!='NA']\n",
    "\n",
    "dict = gensim.corpora.Dictionary(processed_tags)\n",
    "dict.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "#Saving dictionary\n",
    "dict.save('../topic_modeling/lda_dict.dict')\n",
    "bag_of_words_corpus = [dict.doc2bow(tag) for tag in processed_tags]\n",
    "lda_topic_model = gensim.models.LdaMulticore(bag_of_words_corpus, num_topics=7, id2word=dict, passes=2, workers=2)\n",
    "\n",
    "#Saving lda model\n",
    "with open(\"../topic_modeling/lda_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lda_topic_model, f)\n",
    "\n",
    "#Printing topics and correlated words\n",
    "for idx, topic in lda_topic_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
